{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f57d7220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "Built with CUDA support: True\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, logging\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"Built with CUDA support:\", torch.version.cuda is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47431f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mert\\anaconda3\\envs\\lastdl\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Mert\\anaconda3\\envs\\lastdl\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True, low_cpu_mem_usage=True, device_map='cuda', use_safetensors=True, pad_token_id=tokenizer.eos_token_id)\n",
    "#model = AutoModel.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True, low_cpu_mem_usage=True, use_safetensors=True, pad_token_id=tokenizer.eos_token_id)\n",
    "model = model.eval().cuda()\n",
    "#model = model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fff653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 video directories: ['video_1', 'video_2', 'video_3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Frames in video_1: 100%|██████████| 95/95 [03:02<00:00,  1.92s/frame]\n",
      " Frames in video_2: 100%|██████████| 108/108 [01:13<00:00,  1.48frame/s]\n",
      " Frames in video_3: 100%|██████████| 193/193 [02:24<00:00,  1.34frame/s]\n",
      "Videos: 100%|██████████| 3/3 [06:40<00:00, 133.37s/video]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✔ Finished! Wrote 396 rows to c:\\Users\\Mert\\OneDrive\\Desktop\\Deep_Learning_Project\\NoHateZone\\OCR_impl\\ocr_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ─── SUPPRESS TRANSFORMERS WARNINGS ───────────────────────────────────────\n",
    "# Reduce verbosity to hide pad_token_id and attention_mask warnings\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# ─── CONFIG ────────────────────────────────────────────────────────────────\n",
    "local_dir  = \"got_ocr2_0\"            # path to your GOT‑OCR2 model folder\n",
    "frames_dir = Path.cwd() / \"frames\"   # directory containing video_* folders\n",
    "output_csv = Path.cwd() / \"ocr_results.csv\"  # where to save the CSV\n",
    "\n",
    "# ─── LOAD MODEL ────────────────────────────────────────────────────────────\n",
    "# Load tokenizer and model as before\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_dir, trust_remote_code=True)\n",
    "model     = AutoModel.from_pretrained(\n",
    "    local_dir,\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=True,\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=tokenizer.eos_token_id  # set pad_token_id in config\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "model.eval()\n",
    "\n",
    "def clear_cache():\n",
    "    \"\"\"Free up GPU & Python memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def frame_index(path: Path):\n",
    "    \"\"\"Extract trailing integer from filename, or return None.\"\"\"\n",
    "    m = re.search(r\"(\\d+)(?=\\.jpg$)\", path.name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "# ─── MAIN OCR LOOP ─────────────────────────────────────────────────────────\n",
    "records = []\n",
    "video_dirs = sorted(frames_dir.glob(\"video_*\"))\n",
    "print(f\"Found {len(video_dirs)} video directories: {[d.name for d in video_dirs]}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for video_dir in tqdm(video_dirs, desc=\"Videos\", unit=\"video\"):\n",
    "        clear_cache()\n",
    "        frames = sorted(video_dir.glob(\"*.jpg\"), key=lambda p: frame_index(p) or -1)\n",
    "        for frame_path in tqdm(frames, desc=f\" Frames in {video_dir.name}\", unit=\"frame\"):\n",
    "            clear_cache()\n",
    "            try:\n",
    "                result = model.chat(\n",
    "                    tokenizer,\n",
    "                    str(frame_path),\n",
    "                    ocr_type=\"ocr\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {video_dir.name}/{frame_path.name} failed: {e}\")\n",
    "                result = \"<ERROR>\"\n",
    "            records.append({\"video\": video_dir.name, \"frame\": frame_path.name, \"text\": result})\n",
    "\n",
    "# ─── SAVE RESULTS ──────────────────────────────────────────────────────────\n",
    "df = pd.DataFrame(records, columns=[\"video\", \"frame\", \"text\"])\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\\n Finished! Wrote {len(df)} rows to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6198215d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 video directories: ['hate_video_1', 'non_hate_video_425']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Videos: 100%|██████████| 2/2 [02:28<00:00, 74.20s/video] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Finished! Wrote 183 rows to c:\\Users\\Mert\\OneDrive\\Desktop\\Deep_Learning_Project\\NoHateZone\\OCR_impl\\ocr_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, logging\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ─── CONFIG ────────────────────────────────────────────────────────────────\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "cwd        = Path.cwd()\n",
    "local_dir  = cwd  / \"got_ocr2_0\"   # path to your GOT‑OCR2 model folder\n",
    "frames_dir = cwd  / \"frames\"       # directory containing video_* folders\n",
    "output_csv = cwd  / \"ocr_results.csv\"  # where to save the CSV\n",
    "\n",
    "# ─── LOAD MODEL ────────────────────────────────────────────────────────────\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_dir, trust_remote_code=True)\n",
    "model     = AutoModel.from_pretrained(\n",
    "    local_dir,\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=True,\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "model.eval()\n",
    "\n",
    "def clear_cache():\n",
    "    \"\"\"Free up GPU & Python memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def frame_index(path: Path):\n",
    "    \"\"\"Extract trailing integer from filename, or return -1.\"\"\"\n",
    "    m = re.search(r\"(\\d+)(?=\\.jpg$)\", path.name)\n",
    "    return int(m.group(1)) if m else -1\n",
    "\n",
    "# ─── MAIN OCR LOOP ─────────────────────────────────────────────────────────\n",
    "records = []\n",
    "if not frames_dir.exists():\n",
    "    raise FileNotFoundError(f\"Frames directory not found: {frames_dir}\")\n",
    "\n",
    "# find all subfolders named video_* (e.g. hate_video_1, non_hate_video_2)\n",
    "video_dirs = sorted(\n",
    "    [d for d in frames_dir.iterdir() if d.is_dir() and re.match(r\"(?:non_)?hate_video_\\d+$\", d.name)],\n",
    "    key=lambda d: int(re.search(r\"(\\d+)$\", d.name).group(1))\n",
    ")\n",
    "print(f\"Found {len(video_dirs)} video directories: {[d.name for d in video_dirs]}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for video_dir in tqdm(video_dirs, desc=\"Videos\", unit=\"video\"):\n",
    "        clear_cache()\n",
    "        # gather all .jpg frames in sorted order\n",
    "        frames = sorted(video_dir.glob(\"*.jpg\"), key=frame_index)\n",
    "        for frame_path in tqdm(frames, desc=f\"Frames in {video_dir.name}\", unit=\"frame\", leave=False):\n",
    "            clear_cache()\n",
    "            try:\n",
    "                # perform OCR\n",
    "                result = model.chat(\n",
    "                    tokenizer,\n",
    "                    str(frame_path),\n",
    "                    ocr_type=\"ocr\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {video_dir.name}/{frame_path.name} failed: {e}\")\n",
    "                result = \"\"\n",
    "            # record the output\n",
    "            records.append({\n",
    "                \"video\": video_dir.name,\n",
    "                \"frame\": frame_path.name,\n",
    "                \"text\":  result.strip()\n",
    "            })\n",
    "\n",
    "# ─── SAVE RESULTS ──────────────────────────────────────────────────────────\n",
    "df = pd.DataFrame(records, columns=[\"video\", \"frame\", \"text\"])\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\\n✓ Finished! Wrote {len(df)} rows to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eaaffb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "video",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "frame",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d98fd213-f7a3-4fa5-b4d9-fa9566eaa437",
       "rows": [
        [
         "0",
         "hate_video_1",
         "video_1_frame0.jpg",
         "20935021/36129/20150530 11:12"
        ],
        [
         "1",
         "hate_video_1",
         "video_1_frame30.jpg",
         "Along time ago in a galaxy far,  faraway. . ."
        ],
        [
         "2",
         "hate_video_1",
         "video_1_frame60.jpg",
         "Along time ago in a galaxy far,  faraway. . ."
        ],
        [
         "3",
         "hate_video_1",
         "video_1_frame90.jpg",
         "Along time ago in a galaxy far,  faraway. . ."
        ],
        [
         "4",
         "hate_video_1",
         "video_1_frame120.jpg",
         "Along time ago in a galaxy far,  faraway. . ."
        ],
        [
         "5",
         "hate_video_1",
         "video_1_frame150.jpg",
         "Along time ago in a galaxy far,  faraway. . ."
        ],
        [
         "6",
         "hate_video_1",
         "video_1_frame180.jpg",
         "Along time ago in a galaxy far,  faraway. . ."
        ],
        [
         "7",
         "hate_video_1",
         "video_1_frame210.jpg",
         "20935021/36129/20150530 11:12"
        ],
        [
         "8",
         "hate_video_1",
         "video_1_frame240.jpg",
         "20935021/36129/20150530 11:12"
        ],
        [
         "9",
         "hate_video_1",
         "video_1_frame270.jpg",
         "LIM"
        ],
        [
         "10",
         "hate_video_1",
         "video_1_frame300.jpg",
         "LIV"
        ],
        [
         "11",
         "hate_video_1",
         "video_1_frame330.jpg",
         "LACK MATTER!"
        ],
        [
         "12",
         "hate_video_1",
         "video_1_frame360.jpg",
         "BLACK LIVES MATTER!"
        ],
        [
         "13",
         "hate_video_1",
         "video_1_frame390.jpg",
         "BLACK LIVES MATTER!"
        ],
        [
         "14",
         "hate_video_1",
         "video_1_frame420.jpg",
         "BLACK LIVES MATTER!"
        ],
        [
         "15",
         "hate_video_1",
         "video_1_frame450.jpg",
         "BLACK LIVES MATTER!"
        ],
        [
         "16",
         "hate_video_1",
         "video_1_frame480.jpg",
         "BLACK LIVES MATTER!"
        ],
        [
         "17",
         "hate_video_1",
         "video_1_frame510.jpg",
         "BLACK LIVES MATTER!  George Floyd"
        ],
        [
         "18",
         "hate_video_1",
         "video_1_frame540.jpg",
         "BIA G K LIVE E George Floyd"
        ],
        [
         "19",
         "hate_video_1",
         "video_1_frame570.jpg",
         "George Floyd"
        ],
        [
         "20",
         "hate_video_1",
         "video_1_frame600.jpg",
         "George Floyd"
        ],
        [
         "21",
         "hate_video_1",
         "video_1_frame630.jpg",
         "George Floyd"
        ],
        [
         "22",
         "hate_video_1",
         "video_1_frame660.jpg",
         "George Floyd SAY HIS NAME IN"
        ],
        [
         "23",
         "hate_video_1",
         "video_1_frame690.jpg",
         "George Floyd SAY HIS NAME! !"
        ],
        [
         "24",
         "hate_video_1",
         "video_1_frame720.jpg",
         "George Floyd SAY HIS NAME! !"
        ],
        [
         "25",
         "hate_video_1",
         "video_1_frame750.jpg",
         "George Floyd SAY HIS NAME! !"
        ],
        [
         "26",
         "hate_video_1",
         "video_1_frame780.jpg",
         "George Floyd SAY HIS NAME! !"
        ],
        [
         "27",
         "hate_video_1",
         "video_1_frame810.jpg",
         "George Floyd SAY HIS NAME! !"
        ],
        [
         "28",
         "hate_video_1",
         "video_1_frame840.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a"
        ],
        [
         "29",
         "hate_video_1",
         "video_1_frame870.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a"
        ],
        [
         "30",
         "hate_video_1",
         "video_1_frame900.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a blackman was killed. Or should"
        ],
        [
         "31",
         "hate_video_1",
         "video_1_frame930.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should"
        ],
        [
         "32",
         "hate_video_1",
         "video_1_frame960.jpg",
         "George Floyd\nSAY HIS NAME!!\nOver the summer of 2020, a\nblack man was killed. Or should I\ncav nizcar? Better yet"
        ],
        [
         "33",
         "hate_video_1",
         "video_1_frame990.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla."
        ],
        [
         "34",
         "hate_video_1",
         "video_1_frame1020.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla."
        ],
        [
         "35",
         "hate_video_1",
         "video_1_frame1050.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a blackman was killed. Or should say nigger? Better yet, gorilla."
        ],
        [
         "36",
         "hate_video_1",
         "video_1_frame1080.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty"
        ],
        [
         "37",
         "hate_video_1",
         "video_1_frame1110.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty"
        ],
        [
         "38",
         "hate_video_1",
         "video_1_frame1140.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need ot"
        ],
        [
         "39",
         "hate_video_1",
         "video_1_frame1170.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of"
        ],
        [
         "40",
         "hate_video_1",
         "video_1_frame1200.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of"
        ],
        [
         "41",
         "hate_video_1",
         "video_1_frame1230.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of lynching. Fuck all niggers."
        ],
        [
         "42",
         "hate_video_1",
         "video_1_frame1260.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say n lge r? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of lynching. Fuck all niggers."
        ],
        [
         "43",
         "hate_video_1",
         "video_1_frame1290.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a blackman was killed. Or should 1 say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of lynching. Fuck all niggers."
        ],
        [
         "44",
         "hate_video_1",
         "video_1_frame1320.jpg",
         "George Floyd S AY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of lynching. Fuck all niggers."
        ],
        [
         "45",
         "hate_video_1",
         "video_1_frame1350.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a blackman was killed. Or should say nigger? Better yet, gorilla,  Blacks are nasty gorillas/ monkeys in need of lynching. Fuck all niggers."
        ],
        [
         "46",
         "hate_video_1",
         "video_1_frame1380.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of lynching. Fuck all niggers."
        ],
        [
         "47",
         "hate_video_1",
         "video_1_frame1410.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020, a blackman was killed. Or should I say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of lynching. Fuck all niggers."
        ],
        [
         "48",
         "hate_video_1",
         "video_1_frame1440.jpg",
         "George Floyd SAY HIS NAME! !  Over the summer of 2020. a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need of lynching. Fuck all niggers."
        ],
        [
         "49",
         "hate_video_1",
         "video_1_frame1470.jpg",
         "George Floyd SAY HIS NAME M Over the summer of 2020, a black man was killed. Or should say nigger? Better yet, gorilla.  Blacks are nasty gorillas/ monkeys in need ot lynching. Fuck all niggers."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 183
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>frame</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hate_video_1</td>\n",
       "      <td>video_1_frame0.jpg</td>\n",
       "      <td>20935021/36129/20150530 11:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate_video_1</td>\n",
       "      <td>video_1_frame30.jpg</td>\n",
       "      <td>Along time ago in a galaxy far,  faraway. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate_video_1</td>\n",
       "      <td>video_1_frame60.jpg</td>\n",
       "      <td>Along time ago in a galaxy far,  faraway. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate_video_1</td>\n",
       "      <td>video_1_frame90.jpg</td>\n",
       "      <td>Along time ago in a galaxy far,  faraway. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hate_video_1</td>\n",
       "      <td>video_1_frame120.jpg</td>\n",
       "      <td>Along time ago in a galaxy far,  faraway. . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>non_hate_video_425</td>\n",
       "      <td>video_425_frame2490.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>non_hate_video_425</td>\n",
       "      <td>video_425_frame2520.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>non_hate_video_425</td>\n",
       "      <td>video_425_frame2550.jpg</td>\n",
       "      <td>COPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>non_hate_video_425</td>\n",
       "      <td>video_425_frame2580.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>non_hate_video_425</td>\n",
       "      <td>video_425_frame2610.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  video                    frame  \\\n",
       "0          hate_video_1       video_1_frame0.jpg   \n",
       "1          hate_video_1      video_1_frame30.jpg   \n",
       "2          hate_video_1      video_1_frame60.jpg   \n",
       "3          hate_video_1      video_1_frame90.jpg   \n",
       "4          hate_video_1     video_1_frame120.jpg   \n",
       "..                  ...                      ...   \n",
       "178  non_hate_video_425  video_425_frame2490.jpg   \n",
       "179  non_hate_video_425  video_425_frame2520.jpg   \n",
       "180  non_hate_video_425  video_425_frame2550.jpg   \n",
       "181  non_hate_video_425  video_425_frame2580.jpg   \n",
       "182  non_hate_video_425  video_425_frame2610.jpg   \n",
       "\n",
       "                                              text  \n",
       "0                    20935021/36129/20150530 11:12  \n",
       "1    Along time ago in a galaxy far,  faraway. . .  \n",
       "2    Along time ago in a galaxy far,  faraway. . .  \n",
       "3    Along time ago in a galaxy far,  faraway. . .  \n",
       "4    Along time ago in a galaxy far,  faraway. . .  \n",
       "..                                             ...  \n",
       "178                                             12  \n",
       "179                                              5  \n",
       "180                                           COPA  \n",
       "181                                              5  \n",
       "182                                              3  \n",
       "\n",
       "[183 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c83d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lastdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
