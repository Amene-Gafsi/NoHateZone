# NoHateZone

**Our idea**: Use re-annotated meme, texts(tweets), audio speech and video datasets to ‘beep’ out audio chunks and blur out frames in videos where hate speech occurs.
The selected audio chunks and frames are going to fed into a simple neural network whose objective is to classify the object as the source of the hate speech: Race, Ethnicity, Religion and other.

**Introduction**: Social media comprises platforms that allow users to connect with others to expand their knowledge, have a laugh, and discuss issues with global impacts. For social media to serve these purposes, it is essential to foster a safe environment where people can share content and interact without offending, humiliating, or bullying others. According to statistics shared by the FBI’s Uniform Crime Reporting Program, hate crimes occur in three main contexts: gender/sexual orientation, religion, and race/ethnicity. Together, these constitute 96% of the hate crimes reported in the United States in 2024. While social media enables a broad spectrum of self-expression across various topics, hate speech is not defined by its subject matter alone. Rather, hate speech is characterized by language that is hateful, discriminatory, or incites harm (journals.sagepub.com). This distinction underscores that although hate speech may appear in diverse forms, its defining criteria set it apart from general self-expression.

![image](https://github.com/user-attachments/assets/ee8a1653-3d8b-4906-bf61-d99e271cb538)








